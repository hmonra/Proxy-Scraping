ğŸš€ Multithreaded Web Scraper with Selenium and Proxies ğŸ•µï¸â€â™€ï¸

ğŸ“Œ Description

This project is a Web Scraper designed to automate product purchases on the PCComponentes website. It uses multiple threads, Selenium WebDriver, and proxies to maximize speed and avoid being blocked by the website.

âš¡ï¸ Features

âœ… Uses Selenium for automated web interaction.
âœ… Automatic management of cookies and sessions.
âœ… Support for multiple browser windows.
âœ… Real-time notifications to Telegram.
âœ… Automatic logout detection and login retry.
âœ… Automated purchase system when stock is found.

ğŸ—ï¸ Project Structure

ğŸ“¦ Web Scraper Project
â”‚
â”œâ”€â”€ ğŸ“„ main.py           # Main script that runs the scraper loops (1 for each proxy)
â”œâ”€â”€ ğŸ“„ bucle1.py         # Scraper loop 1
â”œâ”€â”€ ğŸ“„ scrap1.py         # Driver and browser configuration 1
â”œâ”€â”€ ğŸ“„ bucle2.py         # Scraper loop 2
â”œâ”€â”€ ğŸ“„ scrap2.py         # Driver and browser configuration 2
â”œâ”€â”€ ğŸ“„ bucle3.py         # Scraper loop 3
â”œâ”€â”€ ğŸ“„ scrap3.py         # Driver and browser configuration 3
â”œâ”€â”€ ğŸ“„ bucle4.py         # Scraper loop 4
â”œâ”€â”€ ğŸ“„ scrap4.py         # Driver and browser configuration 4
â”œâ”€â”€ ğŸ“„ bucle5.py         # Scraper loop 5
â”œâ”€â”€ ğŸ“„ scrap5.py         # Driver and browser configuration 5
â”œâ”€â”€ ğŸ“„ bucle6.py         # Scraper loop 6
â”œâ”€â”€ ğŸ“„ scrap6.py         # Driver and browser configuration 6
â”œâ”€â”€ ğŸ“„ bucle7.py         # Scraper loop 7
â”œâ”€â”€ ğŸ“„ scrap7.py         # Driver and browser configuration 7
â”œâ”€â”€ ğŸ“„ bucle8.py         # Scraper loop 8
â”œâ”€â”€ ğŸ“„ scrap8.py         # Driver and browser configuration 8
â”œâ”€â”€ ğŸ“„ bucle9.py         # Scraper loop 9
â”œâ”€â”€ ğŸ“„ scrap9.py         # Driver and browser configuration 9
â”œâ”€â”€ ğŸ“„ bucle10.py        # Scraper loop 10
â”œâ”€â”€ ğŸ“„ scrap10.py        # Driver and browser configuration 10
â”œâ”€â”€ ğŸ“„ enlace.py         # Contains target links
â”œâ”€â”€ ğŸ“„ requirements.txt  # Project dependencies
â”œâ”€â”€ ğŸ“„ README.md         # This file ğŸ˜

ğŸ”§ Installation

1ï¸âƒ£ Clone this repository:

git clone https://github.com/hmonra/Proxy-Scraping.git

2ï¸âƒ£ Create a virtual environment (optional but recommended):

python -m venv env
source env/bin/activate  # Linux/MacOS
env\Scripts\activate     # Windows

3ï¸âƒ£ Install dependencies:

pip install -r requirements.txt

4ï¸âƒ£ Make sure you have chromedriver in your PATH or specified in the code.

â–¶ï¸ Usage

1ï¸âƒ£ Configure your PCComponentes credentials in scrap10.py.
2ï¸âƒ£ Run the main script:

python main.py

3ï¸âƒ£ The scraper will start scanning for product stock and, if found, will initiate the automated purchase process.

ğŸ“² Telegram Notifications

âœ… The bot is set up to send you real-time updates about:

Products found.

Successful or failed purchase attempts.

Connection problems or logouts.

ğŸ’¬ Set up your own Telegram bot and replace bot_token and bot_chatID in the code.

ğŸ“œ requirements.txt File

selenium
webdriver-manager
pyautogui

ğŸš¨ Warning

âš ï¸ This project is designed for educational purposes only. Scraping websites may violate their terms of service, use it responsibly!

ğŸ¤ Contributions

Contributions are welcome! If you want to improve this scraper, feel free to fork the project and submit a pull request.

ğŸ“ˆ License

This project is under the MIT license. See the LICENSE file for more details.

ğŸ“§ Contact

âœ¨ Developed by @hmonra.
ğŸ“¬ If you have any questions or suggestions, feel free to contact me!

ğŸŒŸ Give the repo a â­ if you found it useful!

